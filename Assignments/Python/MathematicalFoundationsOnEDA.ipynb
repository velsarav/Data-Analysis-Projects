{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical Foundations on Exploratory Data Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please don't modify this function\n",
    "def readDataFrameFromCloudant(database):\n",
    "    cloudantdata=spark.read.load(database, \"org.apache.bahir.cloudant\")\n",
    "\n",
    "    cloudantdata.createOrReplaceTempView(\"washing\")\n",
    "    spark.sql(\"SELECT * from washing\").show()\n",
    "    return cloudantdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All functions can be implemented using DataFrames, ApacheSparkSQL or RDDs. We are only interested in the result. You are given the reference to the data frame in the \"df\" parameter and in case you want to use SQL just use the \"spark\" parameter which is a reference to the global SparkSession object. Finally if you want to use RDDs just use \"df.rdd\" for obtaining a reference to the underlying RDD object. \n",
    "\n",
    "Let's start with the first function. Please calculate the minimal temperature for the test data set you have created. We've provided a little skeleton for you in case you want to use SQL. You can use this skeleton for all subsequent functions. Everything can be implemented using SQL only if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minTemperature(df,spark):\n",
    "    return spark.sql(\"SELECT MIN(temperature) as mintemp from washing\").first().mintemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please now do the same for the mean of the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanTemperature(df,spark):\n",
    "    return spark.sql(\"SELECT AVG(temperature) as meantemp from washing\").first().meantemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please now do the same for the maximum of the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxTemperature(df,spark):\n",
    "    return spark.sql(\"SELECT MAX(temperature) as maxtemp from washing\").first().maxtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please now do the same for the standard deviation of the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdTemperature(df,spark):\n",
    "    return spark.sql(\"SELECT stddev(temperature) as stddtemp from washing\").first().stddtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please now do the same for the skew of the temperature. Since the SQL statement for this is a bit more complicated we've provided a skeleton for you. You have to insert custom code at four position in order to make the function work. Alternatively you can also remove everything and implement if on your own. Note that we are making use of two previously defined functions, so please make sure they are correct. Also note that we are making use of python's string formatting capabilitis where the results of the two function calls to \"meanTemperature\" and \"sdTemperature\" are inserted at the \"%s\" symbols in the SQL string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewTemperature(df,spark):    \n",
    "    return spark.sql(\"\"\"\n",
    "SELECT \n",
    "    (\n",
    "        1/count(temperature)\n",
    "    ) *\n",
    "    SUM (\n",
    "        POWER(temperature-%s,3)/POWER(%s,3)\n",
    "    )\n",
    "\n",
    "as skewtemp from washing\n",
    "                    \"\"\" %(meanTemperature(df,spark),sdTemperature(df,spark))).first().skewtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurtosis is the 4th statistical moment, so if you are smart you can make use of the code for skew which is the 3rd statistical moment. Actually only two things are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosisTemperature(df,spark):    \n",
    "    return spark.sql(\"\"\"\n",
    "SELECT \n",
    "    (\n",
    "        1/count(temperature)\n",
    "    ) *\n",
    "    SUM (\n",
    "        POWER(temperature-%s,4)/POWER(%s,4)\n",
    "    )\n",
    "\n",
    "as kurttemp from washing\n",
    "                    \"\"\" %(meanTemperature(df,spark),sdTemperature(df,spark))).first().kurttemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a hint. This can be solved easily using SQL as well, but as shown in the lecture also using RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationTemperatureHardness(df,spark):\n",
    "    return spark.sql(\"SELECT corr(temperature,hardness) as corrtemphard from washing\").first().corrtemphard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to connect to the cloudant database. Please have a look at the Video \"Overview of end-to-end scenario\" of Week 2 starting from 6:40 in order to learn how to obtain the credentials for the database. Please paste this credentials as strings into the below code\n",
    "\n",
    "### TODO Please provide your Cloudant credentials here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = \"8e9d7d5e-e6f7-4ddc-8a0a-4375b031d58c-bluemix.cloudant.com\"\n",
    "user = \"8e9d7d5e-e6f7-4ddc-8a0a-4375b031d58c-bluemix\"\n",
    "pw = \"545a7c4e03929959d13ba32bbddf84edaaca10048efe428ac4b9ae0c5c183300\"\n",
    "database = \"washing\" #as long as you didn't change this in the NodeRED flow the database name stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n",
      "|                 _id|                _rev|count|flowrate|fluidlevel|frequency|hardness|speed|temperature|           ts|voltage|\n",
      "+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n",
      "|029f45b57ad924ad9...|1-21ca2b5bf2da593...|    9|      11|acceptable|     null|      75| null|         82|1537432207437|   null|\n",
      "|029f45b57ad924ad9...|1-b3a3a8798b7aff4...|   13|      11|acceptable|     null|      72| null|         88|1537432211445|   null|\n",
      "|029f45b57ad924ad9...|1-6eb367ac4f426cd...|    7|    null|      null|       67|    null| null|       null|1537432219430|    231|\n",
      "|029f45b57ad924ad9...|1-8718cbf2d4e06e1...|   22|      11|acceptable|     null|      71| null|        100|1537432220462|   null|\n",
      "|029f45b57ad924ad9...|1-9db802d1338a043...|   10|    null|      null|       70|    null| null|       null|1537432228474|    226|\n",
      "|029f45b57ad924ad9...|1-dfc188106f4b1ca...|   35|      11|acceptable|     null|      70| null|         99|1537432233524|   null|\n",
      "|029f45b57ad924ad9...|1-3a87d8d6b902707...|   41|      11|acceptable|     null|      79| null|         87|1537432239594|   null|\n",
      "|029f45b57ad924ad9...|1-a638d93c342ad6e...|   44|      11|acceptable|     null|      79| null|         90|1537432242609|   null|\n",
      "|029f45b57ad924ad9...|1-7aba06ee3e9557b...|    9|    null|      null|     null|    null| 1049|       null|1537432243426|   null|\n",
      "|029f45b57ad924ad9...|1-66cd58bbfa269a3...|   22|    null|      null|       78|    null| null|       null|1537432264497|    220|\n",
      "|029f45b57ad924ad9...|1-aa4df7870a913bb...|   68|      11|acceptable|     null|      73| null|        100|1537432266679|   null|\n",
      "|029f45b57ad924ad9...|1-599919d99ce402f...|   70|      11|acceptable|     null|      79| null|         87|1537432268680|   null|\n",
      "|029f45b57ad924ad9...|1-824c7d5f29ff0f8...|   81|      11|acceptable|     null|      71| null|         96|1537432279702|   null|\n",
      "|029f45b57ad924ad9...|1-c6fa4f117e1db8a...|   28|    null|      null|       74|    null| null|       null|1537432282509|    222|\n",
      "|029f45b57ad924ad9...|1-9501682b34b8f8c...|   85|      11|acceptable|     null|      73| null|         93|1537432283709|   null|\n",
      "|029f45b57ad924ad9...|1-4784f64e2d5587f...|  128|      11|acceptable|     null|     135| null|         81|1537432326800|   null|\n",
      "|029f45b57ad924ad9...|1-8681b26358d725c...|   43|    null|      null|       80|    null| null|       null|1537432327539|    222|\n",
      "|029f45b57ad924ad9...|1-88c6c3ca48ecc31...|  143|      11|acceptable|     null|      80| null|         84|1537432341826|   null|\n",
      "|029f45b57ad924ad9...|1-898a7f45a2ae312...|  145|      11|acceptable|     null|      79| null|         84|1537432343829|   null|\n",
      "|029f45b57ad924ad9...|1-dce00ead2fd41ba...|  152|      11|acceptable|     null|      74| null|         91|1537432350845|   null|\n",
      "+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Cloudant Spark SQL Example in Python using temp tables\")\\\n",
    "    .config(\"cloudant.host\",hostname)\\\n",
    "    .config(\"cloudant.username\", user)\\\n",
    "    .config(\"cloudant.password\",pw)\\\n",
    "    .getOrCreate()\n",
    "cloudantdata=readDataFrameFromCloudant(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minTemperature(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.00529701097238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanTemperature(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxTemperature(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.096744823430876"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdTemperature(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006068214014430381"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewTemperature(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7743253378919328"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosisTemperature(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007892410440765479"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlationTemperatureHardness(cloudantdata,spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you are done, please download this notebook as python file using the export function and submit is to the gader using the filename \"assignment3.1.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
